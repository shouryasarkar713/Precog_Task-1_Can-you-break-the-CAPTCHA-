{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2lhVs1r_zKD",
        "outputId": "28063cfa-e519-46e3-8d68-43b3dbb83d28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pillow opencv-python numpy nltk matplotlib pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OInUByw0AIu5"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import random\n",
        "# import numpy as np\n",
        "# import cv2\n",
        "# from PIL import Image, ImageDraw, ImageFont\n",
        "# import nltk\n",
        "# from nltk.corpus import words\n",
        "# from matplotlib import font_manager\n",
        "# import pandas as pd\n",
        "\n",
        "# # Download the NLTK words corpus (if not already downloaded)\n",
        "# nltk.download('words', quiet=True)\n",
        "\n",
        "# # ---------------------------\n",
        "# # Utility functions\n",
        "# # ---------------------------\n",
        "\n",
        "# def get_random_word(min_len=5, max_len=10):\n",
        "#     \"\"\"\n",
        "#     Returns a random word from the NLTK words corpus that is all alphabetic\n",
        "#     and whose length is between min_len and max_len.\n",
        "#     \"\"\"\n",
        "#     word_list = [w for w in words.words() if w.isalpha() and min_len <= len(w) <= max_len]\n",
        "#     return random.choice(word_list)\n",
        "\n",
        "# def get_system_fonts():\n",
        "#     \"\"\"\n",
        "#     Returns a list of system TrueType font file paths using matplotlib's font_manager.\n",
        "#     \"\"\"\n",
        "#     font_paths = font_manager.findSystemFonts(fontpaths=\"/content/drive/MyDrive/Google_Webfonts_Package\", fontext='ttf')\n",
        "#     # If no fonts are found, we will rely on PIL's default font.\n",
        "#     return font_paths if font_paths else []\n",
        "\n",
        "# def random_capitalization(word):\n",
        "#     \"\"\"\n",
        "#     Returns the word with randomly assigned capitalization for each letter.\n",
        "#     \"\"\"\n",
        "#     return ''.join(c.upper() if random.random() < 0.5 else c.lower() for c in word)\n",
        "\n",
        "# def create_noisy_background(image_size, background_color=None, sigma=20):\n",
        "#     \"\"\"Creates a noisy background image with Gaussian noise.\"\"\"\n",
        "#     # Create a blank image with the desired size\n",
        "#     background = Image.new('RGB', image_size, color=background_color)\n",
        "#     # Add Gaussian noise to the background image\n",
        "#     noisy_background = add_noise_to_image(background, sigma=sigma)\n",
        "#     return noisy_background\n",
        "\n",
        "# def add_noise_to_image(pil_image, sigma=10):\n",
        "#     \"\"\"\n",
        "#     Adds Gaussian noise to the image using OpenCV.\n",
        "#     \"\"\"\n",
        "#     image_np = np.array(pil_image)\n",
        "#     # Create Gaussian noise\n",
        "#     noise = np.random.normal(0, sigma, image_np.shape).astype(np.uint8)\n",
        "#     noisy_image = cv2.add(image_np, noise)\n",
        "#     return Image.fromarray(noisy_image)\n",
        "\n",
        "# def generate_text_image(word, font_path, image_size=(128, 64), text_color=None,\n",
        "#                         background_color=None, reverse=False, use_noisy_background=False):\n",
        "#     \"\"\"\n",
        "#     Generates an image with the given word rendered on it.\n",
        "#     - If reverse is True, the text is drawn in reverse order.\n",
        "#     - If text_color or background_color is None, random colors are chosen.\n",
        "#     - A random font size is also selected.\n",
        "#     \"\"\"\n",
        "#     padding=10\n",
        "#     # Set default or random colors if not provided.\n",
        "#     if background_color is None:\n",
        "#         # Choose a light background color\n",
        "#         background_color = tuple(random.randint(200, 255) for _ in range(3))\n",
        "#     if text_color is None:\n",
        "#         # Choose a dark text color\n",
        "#         text_color = tuple(random.randint(0, 50) for _ in range(3))\n",
        "\n",
        "#     # Reverse the word if needed.\n",
        "#     display_text = word[::-1] if reverse else word\n",
        "\n",
        "    # # Create a blank image\n",
        "    # if use_noisy_background:\n",
        "    #        image = create_noisy_background(image_size, background_color, sigma=20)\n",
        "    # else:\n",
        "    #        image = Image.new('RGB', image_size, color=background_color)\n",
        "\n",
        "    # draw = ImageDraw.Draw(image)\n",
        "\n",
        "#     # Determine the maximum font size that will allow the text to fit.\n",
        "#     max_font_size = 40\n",
        "#     min_font_size = 10\n",
        "#     font_size = max_font_size\n",
        "\n",
        "#     # Loop to reduce the font size until the text fits with some padding.\n",
        "#     while font_size >= min_font_size:\n",
        "#        try:\n",
        "#          font = ImageFont.truetype(font_path, font_size)\n",
        "#        except Exception:\n",
        "#          font = ImageFont.load_default()\n",
        "#          break\n",
        "\n",
        "#        text_bbox = draw.textbbox((0, 0), display_text, font=font)  # Get bounding box\n",
        "#        text_width = text_bbox[2] - text_bbox[0]\n",
        "#        text_height = text_bbox[3] - text_bbox[1]\n",
        "\n",
        "#        if text_width <= image_size[0] - padding and text_height <= image_size[1] - padding:\n",
        "#           break\n",
        "\n",
        "#        font_size -= 1\n",
        "\n",
        "# # Ensure a minimum font size\n",
        "#     if font_size < min_font_size:\n",
        "#        font_size = min_font_size\n",
        "#        font = ImageFont.truetype(font_path, font_size)\n",
        "#        text_bbox = draw.textbbox((0, 0), display_text, font=font)\n",
        "#        text_width = text_bbox[2] - text_bbox[0]\n",
        "#        text_height = text_bbox[3] - text_bbox[1]\n",
        "\n",
        "#     # Get text size and compute position for centering\n",
        "#     text_bbox = draw.textbbox((0, 0), display_text, font=font)\n",
        "#     text_width = text_bbox[2] - text_bbox[0]  # width is right - left\n",
        "#     text_height = text_bbox[3] - text_bbox[1] # height is bottom - top\n",
        "#     position = ((image_size[0] - text_width) // 2, (image_size[1] - text_height) // 2)\n",
        "\n",
        "#     # Draw the text onto the image\n",
        "#     draw.text(position, display_text, fill=text_color, font=font)\n",
        "#     return image\n",
        "\n",
        "# # ---------------------------\n",
        "# # Dataset Generation Functions\n",
        "# # ---------------------------\n",
        "\n",
        "# def generate_easy_sample(image_size=(128, 64)):\n",
        "#     \"\"\"\n",
        "#     Easy Set:\n",
        "#       - Uses a random word (kept in its original capitalization).\n",
        "#       - Uses a fixed plain white background.\n",
        "#       - Uses a randomly selected system font.\n",
        "#     \"\"\"\n",
        "#     word = get_random_word()\n",
        "#     # Convert the word so that only the first letter is capitalized.\n",
        "#     effective_word = word.capitalize()\n",
        "#     background_color = (255, 255, 255)\n",
        "#     text_color = (0, 0, 0)\n",
        "#     # fonts = get_system_fonts()\n",
        "#     font_path = \"/content/drive/MyDrive/Google_Webfonts_Package/Adamina-Regular.ttf\"\n",
        "#     # Use the original word without random capitalization.\n",
        "#     image = generate_text_image(effective_word, font_path, image_size,\n",
        "#                                 text_color=text_color,\n",
        "#                                 background_color=background_color,\n",
        "#                                 reverse=False)\n",
        "#     return image, effective_word\n",
        "\n",
        "# def generate_hard_sample(image_size=(128, 64)):\n",
        "#     \"\"\"\n",
        "#     Hard Set:\n",
        "#       - Uses a random word with random per-letter capitalization.\n",
        "#       - Uses a random background color (not fixed white) and random text color.\n",
        "#       - Uses a randomly selected system font.\n",
        "#       - Adds Gaussian noise to simulate a noisy environment.\n",
        "#     \"\"\"\n",
        "#     word = get_random_word()\n",
        "#     word = random_capitalization(word)\n",
        "#     # Random background: light color\n",
        "#     background_color = tuple(random.randint(200, 255) for _ in range(3))\n",
        "#     # Random text color: dark color\n",
        "#     text_color = tuple(random.randint(0, 50) for _ in range(3))\n",
        "#     fonts = get_system_fonts()\n",
        "#     font_path = random.choice(fonts) if fonts else None\n",
        "#     image = generate_text_image(word, font_path, image_size,\n",
        "#                                 text_color=text_color,\n",
        "#                                 background_color=background_color,\n",
        "#                                 reverse=False,\n",
        "#                                 use_noisy_background=True)\n",
        "#     # Add noise to the image\n",
        "#     # noisy_image = add_noise_to_image(image, sigma=random.randint(5, 20))\n",
        "#     return image, word\n",
        "\n",
        "# def generate_bonus_sample(image_size=(128, 64)):\n",
        "#     \"\"\"\n",
        "#     Bonus Set:\n",
        "#       - Uses all the variations of the hard set.\n",
        "#       - If the background is red, then the text is rendered reversed,\n",
        "#         but the ground truth remains the original word.\n",
        "#       - Otherwise, it is rendered normally.\n",
        "#       - Background color is chosen randomly between a red-ish and green-ish color.\n",
        "#     \"\"\"\n",
        "#     word = get_random_word()\n",
        "#     # Randomly decide on background color: red-ish or green-ish.\n",
        "#     red_background = (255, random.randint(0, 50), random.randint(0, 50))\n",
        "#     green_background = (random.randint(0, 50), 255, random.randint(0, 50))\n",
        "#     background_color = random.choice([red_background, green_background])\n",
        "#     # Determine whether to reverse text based on background.\n",
        "#     reverse = (background_color[0] == 255)  # if red background, then reverse.\n",
        "#     # Random text and random font\n",
        "#     text_color = tuple(random.randint(0, 50) for _ in range(3))\n",
        "#     fonts = get_system_fonts()\n",
        "#     font_path = random.choice(fonts) if fonts else None\n",
        "#     # For added difficulty, apply random capitalization.\n",
        "#     word_modified = random_capitalization(word)\n",
        "#     image = generate_text_image(word_modified, font_path, image_size,\n",
        "#                                 text_color=text_color,\n",
        "#                                 background_color=background_color,\n",
        "#                                 reverse=reverse)\n",
        "#     # Optionally add noise here as well (using a lower sigma)\n",
        "#     # final_image = add_noise_to_image(image, sigma=random.randint(1, 3))\n",
        "#     # Ground truth remains the original word (not modified or reversed)\n",
        "#     return image, word\n",
        "\n",
        "# def save_image(image, label, output_dir, index, set_name):\n",
        "#     \"\"\"\n",
        "#     Saves the image to the specified directory with a filename that includes the label.\n",
        "#     \"\"\"\n",
        "#     os.makedirs(output_dir, exist_ok=True)\n",
        "#     filename = f\"{set_name}_{index}_{label}.png\"\n",
        "#     filepath = os.path.join(output_dir, filename)\n",
        "#     image.save(filepath)\n",
        "#     return filepath\n",
        "\n",
        "# def generate_dataset_csv(num_samples=50, image_size=(128, 64)):\n",
        "#     \"\"\"\n",
        "#     Generates three datasets (easy, hard, bonus), saves each image, and creates a CSV file\n",
        "#     that records (set, image_path, label) for every sample.\n",
        "#     \"\"\"\n",
        "#     base_dir = \"dataset\"\n",
        "#     os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "#     # Dictionary mapping set names to their generator functions.\n",
        "#     generators = {\n",
        "#         \"easy\": generate_easy_sample,\n",
        "#         \"hard\": generate_hard_sample\n",
        "#         # \"bonus\": generate_bonus_sample\n",
        "#     }\n",
        "\n",
        "#     # List to hold rows for the CSV.\n",
        "#     data_rows = []\n",
        "\n",
        "#     # For each set, generate samples and record image path and label.\n",
        "#     for set_name, generator in generators.items():\n",
        "#         output_dir = os.path.join(base_dir, set_name)\n",
        "#         for i in range(num_samples):\n",
        "#             image, label = generator(image_size=image_size)\n",
        "#             img_path = save_image(image, label, output_dir, i, set_name)\n",
        "#             data_rows.append({\n",
        "#                 \"set\": set_name,\n",
        "#                 \"image_path\": img_path,\n",
        "#                 \"label\": label\n",
        "#             })\n",
        "#             print(f\"Saved {set_name} sample {i}: {label}\")\n",
        "\n",
        "#     # Create a DataFrame and write to CSV.\n",
        "#     df = pd.DataFrame(data_rows)\n",
        "#     csv_path = os.path.join(base_dir, \"dataset.csv\")\n",
        "#     df.to_csv(csv_path, index=False)\n",
        "#     print(f\"CSV file saved at {csv_path}\")\n",
        "\n",
        "# # ---------------------------\n",
        "# # Main Execution\n",
        "# # ---------------------------\n",
        "# if __name__ == \"__main__\":\n",
        "#     NUM_SAMPLES = 200  # Change as desired\n",
        "#     IMAGE_SIZE = (128, 64)\n",
        "\n",
        "#     generate_dataset_csv(num_samples=NUM_SAMPLES, image_size=IMAGE_SIZE)\n",
        "#     print(\"Dataset generation complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lTJV1ounAU54"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # Define the path to your CSV file\n",
        "# csv_path = './dataset/dataset.csv'\n",
        "\n",
        "# # Load the CSV file into a DataFrame\n",
        "# df = pd.read_csv(csv_path)\n",
        "\n",
        "# # Convert the 'label' column to lowercase\n",
        "# df['label'] = df['label'].str.lower()\n",
        "\n",
        "# # Save the updated DataFrame back to CSV (overwriting the original file)\n",
        "# df.to_csv(csv_path, index=False)\n",
        "\n",
        "# print(\"All labels have been converted to lowercase and saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8PA4i1pAWH7",
        "outputId": "bb5df366-bb86-4dbd-a482-572e3730c4e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision pandas pillow matplotlib scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wpLsga-AAZhF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "\n",
        "# For reproducibility\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "# ---------------------------\n",
        "# PARAMETERS\n",
        "# ---------------------------\n",
        "# CSV_PATH = './dataset/dataset.csv'\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 50\n",
        "LEARNING_RATE = 0.001\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# For classification we resize images to 64x128 (height, width) in grayscale.\n",
        "IMAGE_SIZE = (64, 128)\n",
        "\n",
        "# # ---------------------------\n",
        "# # DATASET DEFINITION\n",
        "# # ---------------------------\n",
        "# class OCRClassificationDataset(Dataset):\n",
        "#     \"\"\"\n",
        "#     Custom dataset for OCR classification.\n",
        "#     Expects a CSV with at least the columns \"set\", \"image_path\", and \"label\".\n",
        "#     Only the images whose label is in the selected word set (100 unique words) will be used.\n",
        "#     The images are loaded in grayscale, resized, and normalized.\n",
        "#     \"\"\"\n",
        "#     def __init__(self, csv_file, transform=None, selected_words=None):\n",
        "#         self.data = pd.read_csv(csv_file)\n",
        "#         # Use images from both the \"easy\" and \"hard\" sets.\n",
        "#         self.data = self.data[self.data[\"set\"].isin([\"easy\"])].reset_index(drop=True)\n",
        "#         # If a list of selected_words is provided, filter the dataset accordingly.\n",
        "#         if selected_words is not None:\n",
        "#             self.data = self.data[self.data[\"label\"].isin(selected_words)].reset_index(drop=True)\n",
        "#         self.transform = transform\n",
        "#         self.words = self.data[\"label\"].tolist()\n",
        "#         # Build a mapping for the selected words.\n",
        "#         unique_words = sorted(list(set(self.words)))\n",
        "#         self.word_to_idx = {word: idx for idx, word in enumerate(unique_words)}\n",
        "#         self.idx_to_word = {idx: word for word, idx in self.word_to_idx.items()}\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         row = self.data.iloc[idx]\n",
        "#         img_path = row[\"image_path\"]\n",
        "#         label_word = row[\"label\"]\n",
        "#         try:\n",
        "#             image = Image.open(img_path).convert(\"L\")\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error opening image {img_path}: {e}\")\n",
        "#             raise e\n",
        "#         if self.transform:\n",
        "#             image = self.transform(image)\n",
        "#         label = self.word_to_idx[label_word]\n",
        "#         return image, label\n",
        "\n",
        "# # ---------------------------\n",
        "# # DATA TRANSFORMATIONS\n",
        "# # ---------------------------\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize(IMAGE_SIZE),        # Resize to (64, 128)\n",
        "#     transforms.ToTensor(),                # Convert to tensor (pixel values in [0,1])\n",
        "#     transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "# ])\n",
        "\n",
        "# # ---------------------------\n",
        "# # FILTERING THE DATASET TO 100 WORDS\n",
        "# # ---------------------------\n",
        "# # Load the CSV\n",
        "# df = pd.read_csv(CSV_PATH)\n",
        "# # Filter for the \"easy\" and \"hard\" sets.\n",
        "# df = df[df[\"set\"].isin([\"easy\", \"hard\"])].reset_index(drop=True)\n",
        "# # Get the unique words.\n",
        "# all_words = df[\"label\"].unique().tolist()\n",
        "# if len(all_words) < 100:\n",
        "#     raise ValueError(\"The dataset does not contain at least 100 unique words.\")\n",
        "# # Randomly sample 100 words.\n",
        "# selected_words = random.sample(all_words, 100)\n",
        "# selected_words = sorted(selected_words)\n",
        "# print(f\"Selected {len(selected_words)} classes for classification.\")\n",
        "# # Filter the dataframe for these 100 words.\n",
        "# df_subset = df[df[\"label\"].isin(selected_words)].reset_index(drop=True)\n",
        "# # Save this subset back to CSV (optional) or pass it to the dataset.\n",
        "# subset_csv_path = './dataset/subset_100.csv'\n",
        "# df_subset.to_csv(subset_csv_path, index=False)\n",
        "\n",
        "# # Create the dataset.\n",
        "# dataset = OCRClassificationDataset(subset_csv_path, transform=transform, selected_words=selected_words)\n",
        "# print(f\"Total dataset size for classification: {len(dataset)} samples.\")\n",
        "\n",
        "# # Split dataset into training and test sets (e.g., 80% training, 20% test).\n",
        "# train_size = int(0.8 * len(dataset))\n",
        "# test_size = len(dataset) - train_size\n",
        "# train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "# print(\"Training samples:\", len(train_dataset), \"Test samples:\", len(test_dataset))\n",
        "\n",
        "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# # ---------------------------\n",
        "# # MODEL DEFINITION: A RESNET-18–LIKE ARCHITECTURE\n",
        "# # ---------------------------\n",
        "# # We define a Basic Residual Block.\n",
        "# class BasicBlock(nn.Module):\n",
        "#     expansion = 1\n",
        "\n",
        "#     def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "#         super(BasicBlock, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
        "#                                stride=stride, padding=1, bias=False)\n",
        "#         self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "#         self.relu = nn.ReLU(inplace=True)\n",
        "#         self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "#                                stride=1, padding=1, bias=False)\n",
        "#         self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "#         self.downsample = downsample\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         identity = x\n",
        "\n",
        "#         out = self.conv1(x)\n",
        "#         out = self.bn1(out)\n",
        "#         out = self.relu(out)\n",
        "\n",
        "#         out = self.conv2(out)\n",
        "#         out = self.bn2(out)\n",
        "\n",
        "#         if self.downsample is not None:\n",
        "#             identity = self.downsample(x)\n",
        "#         out += identity\n",
        "#         out = self.relu(out)\n",
        "#         return out\n",
        "\n",
        "# # Define a ResNet classifier.\n",
        "# class ResNetClassifier(nn.Module):\n",
        "#     def __init__(self, block, layers, num_classes, in_channels=1):\n",
        "#         super(ResNetClassifier, self).__init__()\n",
        "#         self.in_channels = 64\n",
        "#         # Initial convolution and pooling.\n",
        "#         self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3,\n",
        "#                                bias=False)  # output: (64, H/2, W/2)\n",
        "#         self.bn1 = nn.BatchNorm2d(64)\n",
        "#         self.relu = nn.ReLU(inplace=True)\n",
        "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # output: (64, H/4, W/4)\n",
        "\n",
        "#         # Residual layers.\n",
        "#         self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "#         self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "#         self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "#         self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "#         # Global average pooling and a fully connected layer.\n",
        "#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "#         self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "#     def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "#         downsample = None\n",
        "#         if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "#             downsample = nn.Sequential(\n",
        "#                 nn.Conv2d(self.in_channels, out_channels * block.expansion,\n",
        "#                           kernel_size=1, stride=stride, bias=False),\n",
        "#                 nn.BatchNorm2d(out_channels * block.expansion),\n",
        "#             )\n",
        "#         layers = []\n",
        "#         layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "#         self.in_channels = out_channels * block.expansion\n",
        "#         for _ in range(1, blocks):\n",
        "#             layers.append(block(self.in_channels, out_channels))\n",
        "#         return nn.Sequential(*layers)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # x: (B, 1, 64, 128)\n",
        "#         x = self.conv1(x)   # -> (B, 64, 32, 64) if input is 64x128\n",
        "#         x = self.bn1(x)\n",
        "#         x = self.relu(x)\n",
        "#         x = self.maxpool(x) # -> (B, 64, 16, 32)\n",
        "#         x = self.layer1(x)  # output shape depends on blocks\n",
        "#         x = self.layer2(x)\n",
        "#         x = self.layer3(x)\n",
        "#         x = self.layer4(x)\n",
        "#         x = self.avgpool(x) # -> (B, 512, 1, 1)\n",
        "#         x = torch.flatten(x, 1)\n",
        "#         x = self.fc(x)\n",
        "#         return x\n",
        "\n",
        "# def ResNet18(num_classes):\n",
        "#     return ResNetClassifier(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
        "\n",
        "# # Instantiate the model.\n",
        "# num_classes = len(selected_words)  # Should be 100.\n",
        "# model = ResNet18(num_classes=num_classes)\n",
        "# model = model.to(DEVICE)\n",
        "# print(model)\n",
        "\n",
        "# # ---------------------------\n",
        "# # LOSS, OPTIMIZER, AND TRAINING SETUP\n",
        "# # ---------------------------\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# def train_classifier(model, train_loader, criterion, optimizer, device, num_epochs=NUM_EPOCHS):\n",
        "#     model.train()\n",
        "#     for epoch in range(num_epochs):\n",
        "#         running_loss = 0.0\n",
        "#         for images, labels in train_loader:\n",
        "#             images = images.to(device)\n",
        "#             labels = labels.to(device)\n",
        "#             optimizer.zero_grad()\n",
        "#             outputs = model(images)\n",
        "#             loss = criterion(outputs, labels)\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "#             running_loss += loss.item() * images.size(0)\n",
        "#         epoch_loss = running_loss / len(train_loader.dataset)\n",
        "#         print(\"Epoch {}/{} Loss: {:.4f}\".format(epoch+1, num_epochs, epoch_loss))\n",
        "#     print(\"Training complete.\")\n",
        "\n",
        "# train_classifier(model, train_loader, criterion, optimizer, DEVICE, num_epochs=NUM_EPOCHS)\n",
        "\n",
        "# def evaluate_classifier(model, test_loader, device):\n",
        "#     model.eval()\n",
        "#     all_preds = []\n",
        "#     all_labels = []\n",
        "#     with torch.no_grad():\n",
        "#         for images, labels in test_loader:\n",
        "#             images = images.to(device)\n",
        "#             outputs = model(images)\n",
        "#             _, preds = torch.max(outputs, 1)\n",
        "#             all_preds.extend(preds.cpu().numpy())\n",
        "#             all_labels.extend(labels.cpu().numpy())\n",
        "#     accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
        "#     print(\"Test Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "#     return all_preds, all_labels\n",
        "\n",
        "# evaluate_classifier(model, test_loader, DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb7sJe_-Nq_u",
        "outputId": "dc9ce51c-d9d0-4fec-8b66-3c3f143fa5a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 30 samples for word: Scavenger\n",
            "Generated 30 samples for word: Evolve\n",
            "Generated 30 samples for word: Vinylene\n",
            "Generated 30 samples for word: Interarmy\n",
            "Generated 30 samples for word: Handwrist\n",
            "Generated 30 samples for word: Hangby\n",
            "Generated 30 samples for word: Biopsic\n",
            "Generated 30 samples for word: Decanter\n",
            "Generated 30 samples for word: Tempery\n",
            "Generated 30 samples for word: Uvulitis\n",
            "Generated 30 samples for word: Purpurate\n",
            "Generated 30 samples for word: Redesire\n",
            "Generated 30 samples for word: Traditor\n",
            "Generated 30 samples for word: Cervus\n",
            "Generated 30 samples for word: Runeword\n",
            "Generated 30 samples for word: Abject\n",
            "Generated 30 samples for word: Tendotome\n",
            "Generated 30 samples for word: Reapply\n",
            "Generated 30 samples for word: Flit\n",
            "Generated 30 samples for word: Helpmate\n",
            "Generated 30 samples for word: Cystoidea\n",
            "Generated 30 samples for word: Gibelite\n",
            "Generated 30 samples for word: Flytail\n",
            "Generated 30 samples for word: Mahoe\n",
            "Generated 30 samples for word: Owerance\n",
            "Generated 30 samples for word: Fungia\n",
            "Generated 30 samples for word: Tideway\n",
            "Generated 30 samples for word: Fagoter\n",
            "Generated 30 samples for word: Overmoist\n",
            "Generated 30 samples for word: Malcolm\n",
            "Generated 30 samples for word: Atragene\n",
            "Generated 30 samples for word: Verdant\n",
            "Generated 30 samples for word: Upgorge\n",
            "Generated 30 samples for word: Gonosomal\n",
            "Generated 30 samples for word: Bucare\n",
            "Generated 30 samples for word: Decylic\n",
            "Generated 30 samples for word: Antarchy\n",
            "Generated 30 samples for word: Tussle\n",
            "Generated 30 samples for word: Benny\n",
            "Generated 30 samples for word: Ocneria\n",
            "Generated 30 samples for word: Strippage\n",
            "Generated 30 samples for word: Vestryish\n",
            "Generated 30 samples for word: Volute\n",
            "Generated 30 samples for word: Seamless\n",
            "Generated 30 samples for word: Mustnt\n",
            "Generated 30 samples for word: Boxen\n",
            "Generated 30 samples for word: Echinate\n",
            "Generated 30 samples for word: Catogenic\n",
            "Generated 30 samples for word: Visorless\n",
            "Generated 30 samples for word: Overcull\n",
            "Generated 30 samples for word: Backstay\n",
            "Generated 30 samples for word: Pagehood\n",
            "Generated 30 samples for word: Footwear\n",
            "Generated 30 samples for word: Silex\n",
            "Generated 30 samples for word: Upsetting\n",
            "Generated 30 samples for word: Perun\n",
            "Generated 30 samples for word: Drama\n",
            "Generated 30 samples for word: Mucorales\n",
            "Generated 30 samples for word: Rhigolene\n",
            "Generated 30 samples for word: Humidify\n",
            "Generated 30 samples for word: Surbater\n",
            "Generated 30 samples for word: Worrying\n",
            "Generated 30 samples for word: Fossiform\n",
            "Generated 30 samples for word: Perfluent\n",
            "Generated 30 samples for word: Reclusely\n",
            "Generated 30 samples for word: Rehoist\n",
            "Generated 30 samples for word: Pursiness\n",
            "Generated 30 samples for word: Swing\n",
            "Generated 30 samples for word: Girlish\n",
            "Generated 30 samples for word: Argention\n",
            "Generated 30 samples for word: Report\n",
            "Generated 30 samples for word: Cultist\n",
            "Generated 30 samples for word: Retaining\n",
            "Generated 30 samples for word: Ivied\n",
            "Generated 30 samples for word: Staccato\n",
            "Generated 30 samples for word: Unvocal\n",
            "Generated 30 samples for word: Foil\n",
            "Generated 30 samples for word: Uranian\n",
            "Generated 30 samples for word: Subtilize\n",
            "Generated 30 samples for word: Epidural\n",
            "Generated 30 samples for word: Chuchona\n",
            "Generated 30 samples for word: Degorge\n",
            "Generated 30 samples for word: Leptiform\n",
            "Generated 30 samples for word: Ovenware\n",
            "Generated 30 samples for word: Progospel\n",
            "Generated 30 samples for word: Carls\n",
            "Generated 30 samples for word: Pongee\n",
            "Generated 30 samples for word: Moorn\n",
            "Generated 30 samples for word: Relbun\n",
            "Generated 30 samples for word: Agpaite\n",
            "Generated 30 samples for word: Greenish\n",
            "Generated 30 samples for word: Hemmel\n",
            "Generated 30 samples for word: Biting\n",
            "Generated 30 samples for word: Volable\n",
            "Generated 30 samples for word: Exilian\n",
            "Generated 30 samples for word: Flambeau\n",
            "Generated 30 samples for word: Trotlet\n",
            "Generated 30 samples for word: Unflighty\n",
            "Generated 30 samples for word: Maleate\n",
            "Generated 30 samples for word: Rheumic\n",
            "CSV saved at ./dataset/easy_dataset.csv\n",
            "ResNetClassifier(\n",
            "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=100, bias=True)\n",
            ")\n",
            "Epoch 1/50, Loss: 4.4565\n",
            "Epoch 2/50, Loss: 3.7015\n",
            "Epoch 3/50, Loss: 3.2484\n",
            "Epoch 4/50, Loss: 2.6925\n",
            "Epoch 5/50, Loss: 2.1402\n",
            "Epoch 6/50, Loss: 1.5440\n",
            "Epoch 7/50, Loss: 1.1418\n",
            "Epoch 8/50, Loss: 0.8471\n",
            "Epoch 9/50, Loss: 0.6253\n",
            "Epoch 10/50, Loss: 0.6109\n",
            "Epoch 11/50, Loss: 0.3915\n",
            "Epoch 12/50, Loss: 0.2977\n",
            "Epoch 13/50, Loss: 0.2853\n",
            "Epoch 14/50, Loss: 0.3282\n",
            "Epoch 15/50, Loss: 0.2511\n",
            "Epoch 16/50, Loss: 0.1785\n",
            "Epoch 17/50, Loss: 0.2146\n",
            "Epoch 18/50, Loss: 0.1164\n",
            "Epoch 19/50, Loss: 0.2285\n",
            "Epoch 20/50, Loss: 0.2205\n",
            "Epoch 21/50, Loss: 0.0998\n",
            "Epoch 22/50, Loss: 0.0966\n",
            "Epoch 23/50, Loss: 0.1109\n",
            "Epoch 24/50, Loss: 0.1522\n",
            "Epoch 25/50, Loss: 0.0592\n",
            "Epoch 26/50, Loss: 0.0987\n",
            "Epoch 27/50, Loss: 0.0984\n",
            "Epoch 28/50, Loss: 0.1199\n",
            "Epoch 29/50, Loss: 0.2068\n",
            "Epoch 30/50, Loss: 0.0495\n",
            "Epoch 31/50, Loss: 0.0688\n",
            "Epoch 32/50, Loss: 0.0487\n",
            "Epoch 33/50, Loss: 0.0363\n",
            "Epoch 34/50, Loss: 0.0878\n",
            "Epoch 35/50, Loss: 0.0851\n",
            "Epoch 36/50, Loss: 0.0541\n",
            "Epoch 37/50, Loss: 0.1184\n",
            "Epoch 38/50, Loss: 0.1623\n",
            "Epoch 39/50, Loss: 0.0493\n",
            "Epoch 40/50, Loss: 0.0143\n",
            "Epoch 41/50, Loss: 0.0669\n",
            "Epoch 42/50, Loss: 0.1926\n",
            "Epoch 43/50, Loss: 0.0857\n",
            "Epoch 44/50, Loss: 0.0404\n",
            "Epoch 45/50, Loss: 0.0124\n",
            "Epoch 46/50, Loss: 0.0184\n",
            "Epoch 47/50, Loss: 0.1675\n",
            "Epoch 48/50, Loss: 0.1897\n",
            "Epoch 49/50, Loss: 0.1700\n",
            "Epoch 50/50, Loss: 0.0975\n",
            "Training complete.\n",
            "Test Accuracy: 99.60%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.996"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from matplotlib import font_manager\n",
        "import nltk\n",
        "nltk.download('words', quiet=True)\n",
        "from nltk.corpus import words as nltk_words\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "\n",
        "# Set random seeds for reproducibility.\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "##############################################\n",
        "# PARAMETERS\n",
        "##############################################\n",
        "NUM_DISTINCT_WORDS = 100         # Number of distinct words (classes)\n",
        "SAMPLES_PER_WORD = 30            # Total samples generated per word (i.e. 30 samples per word)\n",
        "TRAIN_SAMPLES_PER_WORD = 25      # For each word, use 25 samples for training\n",
        "TEST_SAMPLES_PER_WORD = SAMPLES_PER_WORD - TRAIN_SAMPLES_PER_WORD  # The remaining 5 for testing\n",
        "\n",
        "# For Task 0 image generation, we use images of size 2048 x 64 (width, height) in RGB.\n",
        "IMAGE_SIZE_TASK0 = (2048, 64)\n",
        "\n",
        "# For classification, images are converted to grayscale and resized to 64 x 128 (height, width).\n",
        "IMAGE_SIZE = (64, 128)\n",
        "\n",
        "OUTPUT_DIR = \"./dataset/easy\"    # Folder where generated easy-set images will be saved\n",
        "CSV_PATH = \"./dataset/easy_dataset.csv\"  # CSV file to store metadata\n",
        "\n",
        "##############################################\n",
        "# UTILITY FUNCTIONS FOR DATASET GENERATION\n",
        "##############################################\n",
        "\n",
        "def get_distinct_words(n, min_len=4, max_len=9):\n",
        "    \"\"\"Select n distinct words from NLTK corpus that are alphabetic and of length in [min_len, max_len].\"\"\"\n",
        "    word_list = [w for w in nltk_words.words() if w.isalpha() and min_len <= len(w) <= max_len]\n",
        "    word_list = list(set(word_list))\n",
        "    return random.sample(word_list, n)\n",
        "\n",
        "def get_system_fonts():\n",
        "    \"\"\"Return a list of available system TrueType fonts.\"\"\"\n",
        "    font_paths = font_manager.findSystemFonts(fontpaths=\"/content/drive/MyDrive/fontsss\", fontext='ttf')\n",
        "    return font_paths if font_paths else []\n",
        "\n",
        "def generate_text_image(word, font_path, image_size=IMAGE_SIZE_TASK0,\n",
        "                        text_color=(0,0,0), background_color=(255,255,255),\n",
        "                        reverse=False, padding=20):\n",
        "    \"\"\"\n",
        "    Generate an image of given dimensions with the word rendered on it.\n",
        "    If reverse is True, the displayed text is reversed.\n",
        "    The function automatically adjusts font size so that the text fits.\n",
        "    \"\"\"\n",
        "    display_text = word[::-1] if reverse else word\n",
        "    image = Image.new('RGB', image_size, color=background_color)\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    max_font_size = 200\n",
        "    min_font_size = 10\n",
        "    font_size = max_font_size\n",
        "    try:\n",
        "        font = ImageFont.truetype(font_path, font_size)\n",
        "    except IOError:\n",
        "        font = ImageFont.load_default()\n",
        "    while font_size >= min_font_size:\n",
        "        try:\n",
        "            font = ImageFont.truetype(font_path, font_size)\n",
        "        except IOError:\n",
        "            font = ImageFont.load_default()\n",
        "            break\n",
        "        text_bbox = draw.textbbox((0, 0), display_text, font=font)  # Get bounding box\n",
        "        text_width = text_bbox[2] - text_bbox[0]\n",
        "        text_height = text_bbox[3] - text_bbox[1]\n",
        "        if text_width <= image_size[0] - padding and text_height <= image_size[1] - padding:\n",
        "            break\n",
        "        font_size -= 1\n",
        "# Ensure a minimum font size\n",
        "    if font_size < min_font_size:\n",
        "       font_size = min_font_size\n",
        "       font = ImageFont.truetype(font_path, font_size)\n",
        "       text_bbox = draw.textbbox((0, 0), display_text, font=font)\n",
        "       text_width = text_bbox[2] - text_bbox[0]\n",
        "       text_height = text_bbox[3] - text_bbox[1]\n",
        "\n",
        "    # Get text size and compute position for centering\n",
        "    text_bbox = draw.textbbox((0, 0), display_text, font=font)\n",
        "    text_width = text_bbox[2] - text_bbox[0]  # width is right - left\n",
        "    text_height = text_bbox[3] - text_bbox[1] # height is bottom - top\n",
        "    position = ((image_size[0] - text_width) // 2, (image_size[1] - text_height) // 2)\n",
        "\n",
        " # Draw the text onto the image\n",
        "    draw.text(position, display_text, fill=text_color, font=font)\n",
        "    return image\n",
        "\n",
        "def generate_samples_for_word(word, num_samples=SAMPLES_PER_WORD):\n",
        "    \"\"\"\n",
        "    For a given word, generate num_samples images using random fonts.\n",
        "    The word is first capitalized (only first letter capitalized).\n",
        "    Returns a list of dictionaries with keys \"word\" and \"image_path\".\n",
        "    \"\"\"\n",
        "    samples = []\n",
        "    fonts = get_system_fonts()\n",
        "    if not fonts:\n",
        "        raise ValueError(\"No system fonts found!\")\n",
        "    effective_word = word.capitalize()\n",
        "    for i in range(num_samples):\n",
        "        font_path = random.choice(fonts)\n",
        "        img = generate_text_image(effective_word, font_path,\n",
        "                                  image_size=IMAGE_SIZE_TASK0,\n",
        "                                  text_color=(0,0,0),\n",
        "                                  background_color=(255,255,255),\n",
        "                                  reverse=False)\n",
        "        # Create a filename: e.g., \"Hello_0.png\"\n",
        "        filename = f\"{effective_word}_{i}.png\"\n",
        "        file_path = os.path.join(OUTPUT_DIR, filename)\n",
        "        img.save(file_path)\n",
        "        samples.append({\"word\": effective_word, \"image_path\": file_path})\n",
        "    return samples\n",
        "\n",
        "def create_classification_dataset(num_classes=NUM_DISTINCT_WORDS, samples_per_word=SAMPLES_PER_WORD):\n",
        "    \"\"\"\n",
        "    Selects num_classes distinct words and for each word, generates samples_per_word images.\n",
        "    Saves the results into a CSV file.\n",
        "    Returns the list of selected words and the DataFrame.\n",
        "    \"\"\"\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "    selected_words = get_distinct_words(num_classes)\n",
        "    all_samples = []\n",
        "    for word in selected_words:\n",
        "        samples = generate_samples_for_word(word, num_samples=samples_per_word)\n",
        "        all_samples.extend(samples)\n",
        "        print(f\"Generated {len(samples)} samples for word: {word.capitalize()}\")\n",
        "    df = pd.DataFrame(all_samples)\n",
        "    os.makedirs(os.path.dirname(CSV_PATH), exist_ok=True)\n",
        "    df.to_csv(CSV_PATH, index=False)\n",
        "    print(f\"CSV saved at {CSV_PATH}\")\n",
        "    return selected_words, df\n",
        "\n",
        "# Generate the dataset (this will create 3000 images and a CSV file).\n",
        "selected_words, df_generated = create_classification_dataset()\n",
        "\n",
        "##############################################\n",
        "# DATASET CLASS FOR CLASSIFICATION\n",
        "##############################################\n",
        "class OCRClassificationDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom dataset for word classification.\n",
        "    Expects a CSV file with columns: \"word\" and \"image_path\".\n",
        "    The word (label) is used to create a mapping from word to integer.\n",
        "    \"\"\"\n",
        "    def __init__(self, csv_file, transform=None, word_to_idx=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "        self.labels = self.data[\"word\"].tolist()\n",
        "        self.image_paths = self.data[\"image_path\"].tolist()\n",
        "        if word_to_idx is None:\n",
        "            unique_words = sorted(list(set(self.labels)))\n",
        "            self.word_to_idx = {word: idx for idx, word in enumerate(unique_words)}\n",
        "        else:\n",
        "            self.word_to_idx = word_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        try:\n",
        "            image = Image.open(img_path).convert(\"L\")\n",
        "        except Exception as e:\n",
        "            print(\"Error opening image:\", img_path)\n",
        "            raise e\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label_idx = self.word_to_idx[label]\n",
        "        return image, label_idx\n",
        "\n",
        "# Define transformation for classification (images are 64x128 grayscale).\n",
        "transform_class = transforms.Compose([\n",
        "    transforms.Resize(IMAGE_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# Build the dataset.\n",
        "# We'll use the CSV we generated; note that labels in CSV are already capitalized (first letter capitalized).\n",
        "# We build word_to_idx mapping from the selected words.\n",
        "selected_words_sorted = sorted([w.capitalize() for w in selected_words])\n",
        "word_to_idx = {word: idx for idx, word in enumerate(selected_words_sorted)}\n",
        "dataset_cls = OCRClassificationDataset(CSV_PATH, transform=transform_class, word_to_idx=word_to_idx)\n",
        "\n",
        "##############################################\n",
        "# SPLIT DATASET PER CLASS: 25 training samples and 5 test samples per class.\n",
        "##############################################\n",
        "from collections import defaultdict\n",
        "all_indices_by_label = defaultdict(list)\n",
        "for idx, (_, label_idx) in enumerate(dataset_cls):\n",
        "    all_indices_by_label[label_idx].append(idx)\n",
        "\n",
        "train_indices = []\n",
        "test_indices = []\n",
        "for label, indices in all_indices_by_label.items():\n",
        "    # Expect exactly SAMPLES_PER_WORD samples per label (30)\n",
        "    random.shuffle(indices)\n",
        "    train_indices.extend(indices[:TRAIN_SAMPLES_PER_WORD])\n",
        "    test_indices.extend(indices[TRAIN_SAMPLES_PER_WORD:TRAIN_SAMPLES_PER_WORD+TEST_SAMPLES_PER_WORD])\n",
        "\n",
        "from torch.utils.data import Subset\n",
        "train_subset = Subset(dataset_cls, train_indices)\n",
        "test_subset = Subset(dataset_cls, test_indices)\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "##############################################\n",
        "# MODEL DEFINITION: ResNet-18-Like Classifier\n",
        "##############################################\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNetClassifier(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes, in_channels=1):\n",
        "        super(ResNetClassifier, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1,\n",
        "                          stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        # x: (B, 1, 64, 128)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)  # Apply dropout before the fully connected layer.\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "def ResNet18(num_classes):\n",
        "    return ResNetClassifier(BasicBlock, [2,2,2,2], num_classes=num_classes)\n",
        "\n",
        "# Instantiate the model.\n",
        "model_cls = ResNet18(num_classes=len(selected_words))\n",
        "model_cls = model_cls.to(DEVICE)\n",
        "print(model_cls)\n",
        "\n",
        "##############################################\n",
        "# TRAINING SETUP\n",
        "##############################################\n",
        "criterion_cls = nn.CrossEntropyLoss()\n",
        "optimizer_cls = optim.Adam(model_cls.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "def train_classifier(model, train_loader, criterion, optimizer, device, num_epochs=50):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "train_classifier(model_cls, train_loader, criterion_cls, optimizer_cls, DEVICE, num_epochs=NUM_EPOCHS)\n",
        "\n",
        "def evaluate_classifier(model, test_loader, device):\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            total_correct += (preds == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "    accuracy = total_correct / total_samples\n",
        "    print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "    return accuracy\n",
        "\n",
        "evaluate_classifier(model_cls, test_loader, DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classifier(model, test_loader, device):\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            total_correct += (preds == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "    accuracy = total_correct / total_samples\n",
        "    print(f\"Train Accuracy: {accuracy*100:.2f}%\")\n",
        "    return accuracy\n",
        "\n",
        "evaluate_classifier(model_cls, train_loader, DEVICE)"
      ],
      "metadata": {
        "id": "81aZqVO3wvRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "412aa153-9a66-4de6-977b-d328e365fd9f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 99.92%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9992"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_cls, \"model_task1_e.pth\")"
      ],
      "metadata": {
        "id": "i2DIcfVgkzf_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OrMT8FrEsNAK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}